import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report,
    roc_curve,
    auc
)

"""
=============================================================================
K-ARTIMIAUSIÅ² KAIMYNÅ² (k-NN) ALGORITMO DETALUS APRAÅ YMAS
=============================================================================

1. ALGORITMO ESMÄ–:
   k-NN (k-Nearest Neighbors) yra vienas paprasÄiausiÅ³ ir intuityviausiÅ³
   maÅ¡ininio mokymosi algoritmÅ³. Jis remiasi principu: "panaÅ¡Å«s objektai
   yra arti vieni kitÅ³ poÅ¾ymiÅ³ erdvÄ—je".

2. ALGORITMO TIPAS:
   - Priskiriamas "tingaus mokymosi" (lazy learning) algoritmams
   - Instance-based learning algoritmas
   - Non-parametric algoritmas (nedaro prielaidÅ³ apie duomenÅ³ pasiskirstymÄ…)

3. KAIP VEIKIA ALGORITMAS (Å½INGSNIS PO Å½INGSNIO):

   MOKYMO FAZÄ–:
   - Algoritmas TIESIOG Ä®SIMENA visus mokymo duomenis
   - NÄ—ra jokiÅ³ skaiÄiavimÅ³ ar modelio konstravimo
   - Visi duomenys saugomi atmintyje

   KLASIFIKAVIMO FAZÄ– (naujiems duomenims):
   Å½ingsnis 1: ATSTUMO SKAIÄŒIAVIMAS
      - ApskaiÄiuojamas atstumas nuo naujo taÅ¡ko iki VISÅ² mokymo taÅ¡kÅ³
      - DaÅ¾niausiai naudojami atstumai:
        * Euklido: d = âˆš[(xâ‚-xâ‚‚)Â² + (yâ‚-yâ‚‚)Â² + ... + (xâ‚™-yâ‚™)Â²]
        * Manheteno: d = |xâ‚-xâ‚‚| + |yâ‚-yâ‚‚| + ... + |xâ‚™-yâ‚™|

   Å½ingsnis 2: KAIMYNÅ² ATRINKIMAS
      - SurÅ«Å¡iuojami visi taÅ¡kai pagal atstumÄ… (nuo maÅ¾iausio iki didÅ¾iausio)
      - IÅ¡renkami k artimiausi kaimynai

   Å½ingsnis 3: BALSAVIMAS (VOTING)
      - Kiekvienas iÅ¡ k kaimynÅ³ "balsuoja" uÅ¾ savo klasÄ™
      - Naujas taÅ¡kas priskiriamas daugumos klasei
      - Pvz.: jei k=5, ir 3 kaimynai yra klasÄ—s 0, o 2 klasÄ—s 2,
        naujas taÅ¡kas bus priskirtas klasei 0

4. PAGRINDINIAI PARAMETRAI:

   n_neighbors (k):
   - Kiek kaimynÅ³ naudoti klasifikacijai
   - MAÅ½AS k (1-3):
     âœ“ Privalumas: tikslus lokalus sprendimas
     âœ— TrÅ«kumas: jautrus triukÅ¡mui, gali bÅ«ti overfitting
   - DIDELIS k (>20):
     âœ“ Privalumas: stabilesni rezultatai, maÅ¾iau triukÅ¡mo Ä¯takos
     âœ— TrÅ«kumas: gali prarasti detales, underfitting
   - REKOMENDUACIJA: daÅ¾niausiai renkamasi nelyginis skaiÄius
     (pvz., 3, 5, 7, 9), kad iÅ¡vengtÅ³ lygiÅ³jÅ³ balsavime

   metric (atstumo metrika):
   - 'euclidean': tiesus atstumas, labiausiai paplitÄ™s
   - 'manhattan': "miesto kvartalÅ³" atstumas
   - 'minkowski': generalizuotas, su parametru p

   weights (kaimynÅ³ svoriai):
   - 'uniform': visi k kaimynai turi vienodÄ… balsÄ…
   - 'distance': artimesni kaimynai turi didesnÄ¯ svorÄ¯
     (svoris = 1/atstumas)

5. ALGORITMO MATEMATINÄ– IÅ RAIÅ KA:

   KlasÄ—(x_naujas) = argmax Î£(w_i * I(y_i = c))
                     câˆˆC  iâˆˆNk(x)

   Kur:
   - x_naujas: naujas klasifikuojamas taÅ¡kas
   - Nk(x): k artimiausiÅ³ kaimynÅ³ aibÄ—
   - w_i: kaimyno svoris (1 jei uniform, 1/d_i jei distance)
   - I(y_i = c): indikatorinÄ— funkcija (1 jei kaimynas klasÄ—s c, 0 kitaip)
   - C: visÅ³ klasiÅ³ aibÄ—

6. PRIVALUMAI:
   âœ“ Labai paprastas suprasti ir implementuoti
   âœ“ Nereikia mokymo fazÄ—s (greitas "mokymas")
   âœ“ Efektyvus su neliniÅ¡kais duomenimis
   âœ“ Gali bÅ«ti naudojamas klasifikacijai IR regresijai
   âœ“ Lengvai prisitaiko prie naujÅ³ duomenÅ³
   âœ“ Neparametrinis - nedaro prielaidÅ³ apie duomenÅ³ pasiskirstymÄ…

7. TRÅªKUMAI:
   âœ— LÄ—tas klasifikuojant (O(n*d) kur n-objektÅ³ skaiÄius, d-dimensijos)
   âœ— DidelÄ—s atminties sÄ…naudos (reikia saugoti visus mokymo duomenis)
   âœ— Labai jautrus poÅ¾ymiÅ³ skalei (BÅªTINA normalizacija!)
   âœ— Neefektyvus didelÄ—ms duomenÅ³ aibÄ—ms
   âœ— Jautrus irrelevantiems poÅ¾ymiams (curse of dimensionality)
   âœ— Nepasakys, kurie poÅ¾ymiai svarbiausi (no feature importance)

8. KADA NAUDOTI k-NN:
   âœ“ MaÅ¾os-vidutinÄ—s apimties duomenÅ³ aibÄ—s
   âœ“ Kai turime nedaug poÅ¾ymiÅ³ (iki ~20)
   âœ“ Kai duomenÅ³ klasÄ—s persidengiantys arba sudÄ—tingai iÅ¡sibarstÄ™
   âœ“ Kai reikia paprasto baseline modelio
   âœ“ Kai duomenys nÄ—ra labai triukÅ¡mingi

9. TAIKYMAS Å IEMS DUOMENIMS:
   - Turime 2D t-SNE duomenis (tik 2 poÅ¾ymiai) âœ“
   - Duomenys normuoti [0,1] intervale âœ“
   - 2 klasÄ—s (0 ir 2) - binarine klasifikacija âœ“
   - KlasÄ—s nesubalansuotos (96% vs 4%) - reikia atsargumo
   - k-NN puikiai tinka tokiai Å¾emadimensei problemai

10. KLASIFIKAVIMO PROCESO SCHEMA:

    [Mokymo duomenys] â†’ [Saugojimas atmintyje]
                              â†“
    [Naujas taÅ¡kas] â†’ [Atstumo skaiÄiavimas] â†’ [k artimiausiÅ³]
                              â†“                      â†“
                        [Balsavimas] â†’ [KlasÄ—s priskyrimas]

=============================================================================
"""

# Konstantos
RANDOM_STATE = 42
DUOMENU_DIREKTORIJA = 'duomenys'
GRAFIKU_DIREKTORIJA = 'grafikai'
KNN_DIREKTORIJA = 'KNN'

# Sukuriame grafikai/KNN direktorijÄ…
os.makedirs(os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA), exist_ok=True)

# 1. Ä®keliame duomenis
print("=" * 80)
print(" 1. DUOMENÅ² Ä®KÄ–LIMAS IR PARUOÅ IMAS ".center(80, "="))
print("=" * 80)

try:
    df_mokymas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'mokymo_aibe.csv'),
        sep=';'
    )
    df_validavimas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'validavimo_aibe.csv'),
        sep=';'
    )
    df_testavimas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'testavimo_aibe.csv'),
        sep=';'
    )
except FileNotFoundError:
    # Fallback if running from parent directory
    DUOMENU_DIREKTORIJA = '4laboratorinis/duomenys'
    GRAFIKU_DIREKTORIJA = '4laboratorinis/grafikai'
    os.makedirs(os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA), exist_ok=True)

    df_mokymas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'mokymo_aibe.csv'),
        sep=';'
    )
    df_validavimas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'validavimo_aibe.csv'),
        sep=';'
    )
    df_testavimas = pd.read_csv(
        os.path.join(DUOMENU_DIREKTORIJA, 'testavimo_aibe.csv'),
        sep=';'
    )

# Atskiriam poÅ¾ymius (X) ir klases (y)
X_mokymas = df_mokymas.drop(columns='label').values
y_mokymas = df_mokymas['label'].values

X_validavimas = df_validavimas.drop(columns='label').values
y_validavimas = df_validavimas['label'].values

X_testavimas = df_testavimas.drop(columns='label').values
y_testavimas = df_testavimas['label'].values

print(f"âœ“ Mokymo aibÄ—: {X_mokymas.shape[0]} Ä¯raÅ¡Å³, {X_mokymas.shape[1]} poÅ¾ymiai")
print(f"âœ“ Validavimo aibÄ—: {X_validavimas.shape[0]} Ä¯raÅ¡Å³")
print(f"âœ“ Testavimo aibÄ—: {X_testavimas.shape[0]} Ä¯raÅ¡Å³")

# 3. HiperparametrÅ³ parinkimas (Tuning)
print("\n" + "=" * 80)
print(" 3. HIPERPARAMETRÅ² PARINKIMAS (k REIKÅ MÄ–S) ".center(80, "="))
print("=" * 80)

print("\nTiriamos k reikÅ¡mÄ—s: nuo 1 iki 21 (nelyginiai skaiÄiai)")
print("Tikslas: rasti optimalÅ³ k, kuris duotÅ³ geriausiÄ… F1 balÄ… validavimo aibÄ—je")
print()

k_values = range(1, 22, 2)  # 1, 3, 5, ..., 21
results = []

print(f"{'k':<5} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1 Score':<10}")
print("-" * 60)

best_k = -1
best_f1 = -1
best_accuracy = -1

for k in k_values:
    # Sukuriame k-NN klasifikatoriÅ³ su dabartine k reikÅ¡me
    knn = KNeighborsClassifier(
        n_neighbors=k,
        metric='manhattan',  # Euklido atstumas
        weights='uniform'     # Visi kaimynai turi vienodÄ… svorÄ¯
    )

    # Apmokiname modelÄ¯
    knn.fit(X_mokymas, y_mokymas)

    # Prognozuojame validavimo aibÄ™
    y_val_pred = knn.predict(X_validavimas)

    # SkaiÄiuojame metrikos
    acc = accuracy_score(y_validavimas, y_val_pred)
    prec = precision_score(y_validavimas, y_val_pred, average='weighted')
    rec = recall_score(y_validavimas, y_val_pred, average='weighted')
    f1 = f1_score(y_validavimas, y_val_pred, average='weighted')

    results.append({
        'k': k,
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1': f1
    })

    print(f"{k:<5} | {acc:.4f}     | {prec:.4f}     | {rec:.4f}     | {f1:.4f}")

    # Saugome geriausiÄ… k
    if f1 > best_f1:
        best_f1 = f1
        best_k = k
        best_accuracy = acc

print("-" * 60)
print(f"\nğŸ† GERIAUSIAS k = {best_k}")
print(f"   Accuracy: {best_accuracy:.4f}")
print(f"   F1 Score: {best_f1:.4f}")

# Vizualizuojame parametrÅ³ paieÅ¡kÄ…
results_df = pd.DataFrame(results)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Accuracy
axes[0, 0].plot(results_df['k'], results_df['accuracy'], marker='o', linewidth=2)
axes[0, 0].axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k}')
axes[0, 0].set_xlabel('KaimynÅ³ skaiÄius (k)')
axes[0, 0].set_ylabel('Accuracy')
axes[0, 0].set_title('Tikslumo (Accuracy) priklausomybÄ— nuo k')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].set_xticks(k_values)

# Precision
axes[0, 1].plot(results_df['k'], results_df['precision'], marker='s', color='green', linewidth=2)
axes[0, 1].axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k}')
axes[0, 1].set_xlabel('KaimynÅ³ skaiÄius (k)')
axes[0, 1].set_ylabel('Precision')
axes[0, 1].set_title('Precizijos (Precision) priklausomybÄ— nuo k')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)
axes[0, 1].set_xticks(k_values)

# Recall
axes[1, 0].plot(results_df['k'], results_df['recall'], marker='^', color='orange', linewidth=2)
axes[1, 0].axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k}')
axes[1, 0].set_xlabel('KaimynÅ³ skaiÄius (k)')
axes[1, 0].set_ylabel('Recall')
axes[1, 0].set_title('AtÅ¡aukimo (Recall) priklausomybÄ— nuo k')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)
axes[1, 0].set_xticks(k_values)

# F1 Score
axes[1, 1].plot(results_df['k'], results_df['f1'], marker='D', color='purple', linewidth=2)
axes[1, 1].axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k}')
axes[1, 1].set_xlabel('KaimynÅ³ skaiÄius (k)')
axes[1, 1].set_ylabel('F1 Score')
axes[1, 1].set_title('F1 balo priklausomybÄ— nuo k')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)
axes[1, 1].set_xticks(k_values)

plt.suptitle('k-NN HiperparametrÅ³ Ä¯taka klasifikavimo kokybei (Validavimo aibÄ—)',
             fontsize=14, y=0.995)
plt.tight_layout()
plt.savefig(
    os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA, 'parameter_tuning_detailed.png'),
    dpi=300
)
plt.close()

# Visos metrikos viename grafike
plt.figure(figsize=(12, 6))
plt.plot(results_df['k'], results_df['accuracy'], marker='o', label='Accuracy', linewidth=2)
plt.plot(results_df['k'], results_df['precision'], marker='s', label='Precision', linewidth=2)
plt.plot(results_df['k'], results_df['recall'], marker='^', label='Recall', linewidth=2)
plt.plot(results_df['k'], results_df['f1'], marker='D', label='F1 Score', linewidth=2)
plt.axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k}')
plt.xlabel('KaimynÅ³ skaiÄius (k)', fontsize=12)
plt.ylabel('Metrikos reikÅ¡mÄ—', fontsize=12)
plt.title('k-NN: VisÅ³ metrikÅ³ palyginimas', fontsize=14)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.xticks(k_values)
plt.tight_layout()
plt.savefig(
    os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA, 'all_metrics_comparison.png'),
    dpi=300
)
plt.close()

print("âœ“ ParametrÅ³ parinkimo grafikai iÅ¡saugoti")

# 4. Galutinis modelio mokymas
print("\n" + "=" * 80)
print(f" 4. GALUTINIO MODELIO MOKYMAS (k={best_k}) ".center(80, "="))
print("=" * 80)

final_knn = KNeighborsClassifier(
    n_neighbors=best_k,
    metric='euclidean',
    weights='uniform'
)
final_knn.fit(X_mokymas, y_mokymas)

print(f"âœ“ Modelis sÄ—kmingai apmokytas!")
print(f"  Parametrai:")
print(f"    - n_neighbors (k): {best_k}")
print(f"    - metric: euclidean")
print(f"    - weights: uniform")
print(f"  Mokymo duomenÅ³ kiekis: {len(X_mokymas)}")

# 5. Prognozuojame ir vertiname
print("\n" + "=" * 80)
print(" 5. MODELIO VERTINIMAS ".center(80, "="))
print("=" * 80)

# PrognozÄ—s
y_mokymas_pred = final_knn.predict(X_mokymas)
y_validavimas_pred = final_knn.predict(X_validavimas)
y_testavimas_pred = final_knn.predict(X_testavimas)

# Funkcija metrikoms spausdinti
def spausdinti_metrikos(y_tikros, y_prognozes, rinkinys_pavadinimas):
    acc = accuracy_score(y_tikros, y_prognozes)
    prec = precision_score(y_tikros, y_prognozes, average='weighted')
    rec = recall_score(y_tikros, y_prognozes, average='weighted')
    f1 = f1_score(y_tikros, y_prognozes, average='weighted')

    print(f"\n{'â”€'*50}")
    print(f"{rinkinys_pavadinimas:^50}")
    print(f"{'â”€'*50}")
    print(f"  Tikslumas (Accuracy):   {acc:.4f} ({acc*100:.2f}%)")
    print(f"  Precizija (Precision):  {prec:.4f}")
    print(f"  AtÅ¡aukimas (Recall):    {rec:.4f}")
    print(f"  F1 balas:               {f1:.4f}")
    print(f"{'â”€'*50}")

    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}

metrikos_mokymas = spausdinti_metrikos(y_mokymas, y_mokymas_pred, "MOKYMO AIBÄ–")
metrikos_validavimas = spausdinti_metrikos(y_validavimas, y_validavimas_pred, "VALIDAVIMO AIBÄ–")
metrikos_testavimas = spausdinti_metrikos(y_testavimas, y_testavimas_pred, "TESTAVIMO AIBÄ–")

# Palyginimo lentelÄ—
print("\n" + "=" * 80)
print(" METRIKÅ² PALYGINIMAS ".center(80, "="))
print("=" * 80)

comparison_df = pd.DataFrame({
    'Mokymo aibÄ—': metrikos_mokymas,
    'Validavimo aibÄ—': metrikos_validavimas,
    'Testavimo aibÄ—': metrikos_testavimas
})

print(comparison_df.to_string())

# Vizualizuojame metrikas
fig, ax = plt.subplots(figsize=(10, 6))
comparison_df.T.plot(kind='bar', ax=ax)
ax.set_title('k-NN Klasifikavimo metrikÅ³ palyginimas', fontsize=14)
ax.set_xlabel('DuomenÅ³ rinkinys', fontsize=12)
ax.set_ylabel('Metrikos reikÅ¡mÄ—', fontsize=12)
ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
ax.legend(title='Metrika', bbox_to_anchor=(1.05, 1), loc='upper left')
ax.grid(True, alpha=0.3, axis='y')
ax.set_ylim([0, 1.1])
plt.tight_layout()
plt.savefig(
    os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA, 'metrics_comparison.png'),
    dpi=300
)
plt.close()

# 6. Detalus klasifikacijos ataskaita
print("\n" + "=" * 80)
print(" 6. DETALI KLASIFIKACIJOS ATASKAITA (TESTAVIMO AIBÄ–) ".center(80, "="))
print("=" * 80)

print(classification_report(
    y_testavimas,
    y_testavimas_pred,
    target_names=['KlasÄ— 0 (NormalÅ«s)', 'KlasÄ— 2 (Aritmija)'],
    digits=4
))

# 7. Painiavos matrica (Confusion Matrix)
print("\n" + "=" * 80)
print(" 7. PAINIAVOS MATRICA ".center(80, "="))
print("=" * 80)

# SkaiÄiuojame painiavos matricas
cm_mokymas = confusion_matrix(y_mokymas, y_mokymas_pred)
cm_validavimas = confusion_matrix(y_validavimas, y_validavimas_pred)
cm_testavimas = confusion_matrix(y_testavimas, y_testavimas_pred)

# Spausdiname testavimo matricos detales
print("\nTestavimo aibÄ—s painiavos matrica:")
print(f"\n{'':>15} | {'PrognozÄ— 0':>12} | {'PrognozÄ— 2':>12}")
print("-" * 45)
print(f"{'Tikroji 0':>15} | {cm_testavimas[0,0]:>12} | {cm_testavimas[0,1]:>12}")
print(f"{'Tikroji 2':>15} | {cm_testavimas[1,0]:>12} | {cm_testavimas[1,1]:>12}")

print(f"\nTeisingai klasifikuota: {cm_testavimas[0,0] + cm_testavimas[1,1]} "
      f"({((cm_testavimas[0,0] + cm_testavimas[1,1])/len(y_testavimas)*100):.2f}%)")
print(f"Klaidingai klasifikuota: {cm_testavimas[0,1] + cm_testavimas[1,0]} "
      f"({((cm_testavimas[0,1] + cm_testavimas[1,0])/len(y_testavimas)*100):.2f}%)")

# Vizualizuojame painiavos matricas
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

for idx, (cm, title) in enumerate([
    (cm_mokymas, 'Mokymo aibÄ—'),
    (cm_validavimas, 'Validavimo aibÄ—'),
    (cm_testavimas, 'Testavimo aibÄ—')
]):
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=['KlasÄ— 0', 'KlasÄ— 2'],
        yticklabels=['KlasÄ— 0', 'KlasÄ— 2'],
        ax=axes[idx],
        cbar_kws={'label': 'Kiekis'}
    )
    axes[idx].set_title(f'{title}\n(Accuracy: {accuracy_score(
        [y_mokymas, y_validavimas, y_testavimas][idx],
        [y_mokymas_pred, y_validavimas_pred, y_testavimas_pred][idx]
    ):.4f})')
    axes[idx].set_ylabel('Tikra klasÄ—')
    axes[idx].set_xlabel('Prognozuota klasÄ—')

plt.suptitle(f'Painiavos matricos (k-NN, k={best_k})', fontsize=14, y=1.02)
plt.tight_layout()
plt.savefig(
    os.path.join(GRAFIKU_DIREKTORIJA, KNN_DIREKTORIJA, 'confusion_matrices.png'),
    dpi=300
)
plt.close()

print("âœ“ Painiavos matricos vizualizacija iÅ¡saugota")

# 8. KlaidÅ³ analizÄ—
print("\n" + "=" * 80)
print(" 8. KLAIDÅ² ANALIZÄ– ".center(80, "="))
print("=" * 80)

klaidos_maska = y_testavimas != y_testavimas_pred
klaidingi_indeksai = np.where(klaidos_maska)[0]
klaidingi_X = X_testavimas[klaidos_maska]
klaidingi_y_tikri = y_testavimas[klaidos_maska]
klaidingi_y_pred = y_testavimas

print("\n" + "="*80)
print(" 9. KITÅ² ALGORITMÅ² PALYGINIMAS: NB, TREE, RF ".center(80, "="))
print("="*80)

from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

ALG_DIREKTORIJA = os.path.join(GRAFIKU_DIREKTORIJA, "KITIALGORITMAI")
os.makedirs(ALG_DIREKTORIJA, exist_ok=True)

# 1. ALGORITMÅ² SÄ„RAÅ AS
algoritmai = {
    "KNN": final_knn,
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=RANDOM_STATE),
    "Random Forest": RandomForestClassifier(
        n_estimators=150,
        max_depth=None,
        random_state=RANDOM_STATE
    )
}

# 2. METRIKÅ² IR ROC REIKÅ MIÅ² TALPYKLA
rezultatai = {}
roc_duomenys = {}

# 3. VISÅ² ALGORITMÅ² TRENIRAVIMAS IR VERTINIMAS
for pavadinimas, modelis in algoritmai.items():
    print("\n" + "-"*60)
    print(f" ALGORITMAS: {pavadinimas}".center(60))
    print("-"*60)

    # Apmokymas
    modelis.fit(X_mokymas, y_mokymas)

    # PrognozÄ—s
    y_pred = modelis.predict(X_testavimas)

    # Metrikos
    acc = accuracy_score(y_testavimas, y_pred)
    prec = precision_score(y_testavimas, y_pred, average="weighted")
    rec = recall_score(y_testavimas, y_pred, average="weighted")
    f1 = f1_score(y_testavimas, y_pred, average="weighted")

    rezultatai[pavadinimas] = {
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1": f1
    }

    # Painiavos matrica
    cm = confusion_matrix(y_testavimas, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, cmap="Blues", fmt="d",
                xticklabels=["0", "2"], yticklabels=["0", "2"])
    plt.title(f"{pavadinimas} Painiavos matrica")
    plt.xlabel("Prognozuota")
    plt.ylabel("Tikra")
    plt.tight_layout()
    plt.savefig(os.path.join(ALG_DIREKTORIJA, f"{pavadinimas}_confusion.png"))
    plt.close()

    # ROC (tik tiems, kurie turi predict_proba)
    if hasattr(modelis, "predict_proba"):
        y_proba = modelis.predict_proba(X_testavimas)[:, 1]
        fpr, tpr, _ = roc_curve(y_testavimas, y_proba, pos_label=2)
        roc_duomenys[pavadinimas] = (fpr, tpr)

    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:    {rec:.4f}")
    print(f"F1 Score:  {f1:.4f}")


print("\n" + "="*80)
print(" 9â€“11 Å½INGSNIAI: ATSITIKTINÄ– POÅ½YMIÅ² PERMUTACIJA ".center(80, "="))
print("="*80)

from copy import deepcopy

# 9 Å¾ingsnis â€“ atsitiktinai sumaiÅ¡yti poÅ¾ymiÅ³ reikÅ¡mes
def permutuoti_pozymius(X):
    X_permutuotas = deepcopy(X)
    for col in range(X.shape[1]):
        np.random.shuffle(X_permutuotas[:, col])
    return X_permutuotas

X_mokymas_perm = permutuoti_pozymius(X_mokymas)
X_validavimas_perm = permutuoti_pozymius(X_validavimas)
X_testavimas_perm = permutuoti_pozymius(X_testavimas)

# 10 Å¾ingsnis â€“ treniruoti modelÄ¯ naujoje permutuotoje erdvÄ—je
knn_perm = KNeighborsClassifier(
    n_neighbors=best_k,
    metric='euclidean',
    weights='uniform'
)
knn_perm.fit(X_mokymas_perm, y_mokymas)

# 11 Å¾ingsnis â€“ Ä¯vertinti permutuoto modelio veikimÄ…
y_test_pred_perm = knn_perm.predict(X_testavimas_perm)

acc_perm = accuracy_score(y_testavimas, y_test_pred_perm)
prec_perm = precision_score(y_testavimas, y_test_pred_perm, average='weighted')
rec_perm = recall_score(y_testavimas, y_test_pred_perm, average='weighted')
f1_perm = f1_score(y_testavimas, y_test_pred_perm, average='weighted')

print("\nRezultatai po atsitiktinÄ—s poÅ¾ymiÅ³ permutacijos:")
print(f"  Accuracy:  {acc_perm:.4f}")
print(f"  Precision: {prec_perm:.4f}")
print(f"  Recall:    {rec_perm:.4f}")
print(f"  F1-score:  {f1_perm:.4f}")

print("\n--- PALYGINIMAS (originalus vs permutuotas) ---")
print(f"Originalus F1:   {metrikos_testavimas['f1']:.4f}")
print(f"Permutuoto F1:   {f1_perm:.4f}")

if f1_perm < metrikos_testavimas['f1'] * 0.5:
    print("\nâœ“ Klasifikatorius teisingai naudoja poÅ¾ymius â€” permutacija smarkiai pablogino rezultatus.")
else:
    print("\nâš ï¸ DÄ–MESIO: permutacija smarkiai nesumaÅ¾ino veikimo â€” poÅ¾ymiai gali bÅ«ti neinformatyvÅ«s.")

print("\n" + "="*80)
print(" BENDRA ROC/AUC DIAGRAMA VISIEMS ALGORITMAMS ".center(80, "="))
print("="*80)

plt.figure(figsize=(8, 6))

auc_lentele = {}

for alg, (fpr, tpr) in roc_duomenys.items():
    auc_val = auc(fpr, tpr)
    auc_lentele[alg] = auc_val
    plt.plot(fpr, tpr, linewidth=2, label=f"{alg} (AUC={auc_val:.3f})")

plt.plot([0, 1], [0, 1], "k--", label="Random guess")

plt.title("ROC kreivÄ—s palyginimas (KNN, NB, Tree, RF)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)

plt.savefig(os.path.join(ALG_DIREKTORIJA, "ROC_ALL_MODELS.png"), dpi=300)
plt.close()

print("âœ“ Bendra ROC kreivÄ— sugeneruota")
print("\nAUC reikÅ¡mÄ—s:")
for alg, val in auc_lentele.items():
    print(f"  {alg}: {val:.4f}")

